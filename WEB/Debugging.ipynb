{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "import joblib\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from P7_functions import CustTransformer\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data train et test sets\n",
    "with open('data\\\\dict_cleaned_samp.pkl', 'rb') as file:\n",
    "    dict_cleaned = dill.load(file)\n",
    "\n",
    "# Best model and best threshold\n",
    "with open('model\\\\bestmodel_thresh.pkl', 'rb') as file:\n",
    "    best_model, thresh = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveaux pickles avec joblib\n",
    "\n",
    "import joblib\n",
    "with open('data\\\\bestmodel_joblib.pkl', 'wb') as file:\n",
    "    joblib.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unpickle with pickle\n",
    "\n",
    "# with open('data\\\\bestmodel_thresh_pickle.pkl', 'rb') as file:\n",
    "#     best_model, thresh = pickle.load(file)\n",
    "# with open('data\\\\dict_cleaned_samp_pickle.pkl', 'rb') as file:\n",
    "#     dict_cleaned = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  nouveau mod√®le tout simple\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_tr_featsel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc',\n",
       "                 CustTransformer(strat_high_card='loo', thresh_card=8)),\n",
       "                ('featsel',\n",
       "                 SelectFromModel(estimator=LGBMClassifier(), max_features=64)),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(extra_trees=True, is_unbalance=True,\n",
       "                                learning_rate=0.034600991954157015, max_depth=3,\n",
       "                                n_estimators=1071, num_leaves=85,\n",
       "                                random_state=14, reg_alpha=0.001815601938420407,\n",
       "                                reg_lambda=0.1168368098621301))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_transformer import CustTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the steps of the pipeline from zero\n",
    "preproc_step = CustTransformer(strat_high_card='loo', thresh_card=8)\n",
    "featsel_step = SelectFromModel(estimator=LGBMClassifier(), max_features=64)\n",
    "clf_step = LGBMClassifier(extra_trees=True, is_unbalance=True,\n",
    "                                learning_rate=0.034600991954157015, max_depth=3,\n",
    "                                n_estimators=1071, num_leaves=85,\n",
    "                                random_state=14, reg_alpha=0.001815601938420407,\n",
    "                                reg_lambda=0.1168368098621301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproc_step = best_model.named_steps['preproc']\n",
    "# featsel_step = best_model.named_steps['featsel']\n",
    "# clf_step = best_model.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump separately the three steps of the pipeline\n",
    "with open('data\\\\preproc_step.pkl', 'wb') as file:\n",
    "    joblib.dump(preproc_step, file)\n",
    "with open('data\\\\featsel_step.pkl', 'wb') as file:\n",
    "    joblib.dump(featsel_step, file)\n",
    "with open('data\\\\clf_step.pkl', 'wb') as file:\n",
    "    joblib.dump(clf_step, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle with joblib\n",
    "\n",
    "with open('data\\\\bestmodel_thresh_joblib.pkl', 'rb') as file:\n",
    "    best_model, thresh = joblib.load(file)\n",
    "with open('data\\\\dict_cleaned_samp_joblib.pkl', 'rb') as file:\n",
    "    dict_cleaned = joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'X_train.csv')\n",
    "X_train = pd.read_csv(path, index_col='SK_ID_CURR')\n",
    "path = os.path.join('data', 'y_train.csv')\n",
    "y_train = pd.read_csv(path, index_col='SK_ID_CURR')\n",
    "path = os.path.join('data', 'X_test.csv')\n",
    "X_test = pd.read_csv(path, index_col='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 70), (20000, 1), (5000, 70))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pipeline([('preproc', preproc_step),\n",
    "\t                   ('featsel', featsel_step),\n",
    "                       ('clf', clf_step)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc',\n",
       "                 CustTransformer(strat_high_card='loo', thresh_card=8)),\n",
       "                ('featsel',\n",
       "                 SelectFromModel(estimator=LGBMClassifier(), max_features=64)),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(extra_trees=True, is_unbalance=True,\n",
       "                                learning_rate=0.034600991954157015, max_depth=3,\n",
       "                                n_estimators=1071, num_leaves=85,\n",
       "                                random_state=14, reg_alpha=0.001815601938420407,\n",
       "                                reg_lambda=0.1168368098621301))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute processed data (first steps of the best_model pipeline)\n",
    "# X_train = dict_cleaned['X_train']\n",
    "# y_train = dict_cleaned['y_train']\n",
    "# X_test = dict_cleaned['X_test']\n",
    "\n",
    "# # split the steps of the best pipeline\n",
    "# preproc_step = best_model.named_steps['preproc']\n",
    "# featsel_step = best_model.named_steps['featsel']\n",
    "# clf_step = best_model.named_steps['clf']\n",
    "\n",
    "# compute the preprocessed data (encoding and standardization)\n",
    "X_tr_prepro = preproc_step.transform(X_train)\n",
    "X_te_prepro = preproc_step.transform(X_test)\n",
    "# get the name of the columns after encoding\n",
    "preproc_cols = X_tr_prepro.columns\n",
    "# get the name of the columns selected using SelectFromModel\n",
    "featsel_cols = preproc_cols[featsel_step.get_support()]\n",
    "# compute the data to be used by the best classifier\n",
    "X_tr_featsel = X_tr_prepro[featsel_cols]\n",
    "X_te_featsel = X_te_prepro[featsel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([100007, 100009, 100010, 100012, 100022, 100029, 100040, 100041,\n",
       "            100086, 100130,\n",
       "            ...\n",
       "            456094, 456099, 456125, 456129, 456143, 456147, 456165, 456187,\n",
       "            456191, 456236],\n",
       "           dtype='int64', name='SK_ID_CURR', length=20000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_featsel.index.sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
